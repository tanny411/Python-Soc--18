{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Day 1: Introduction to Machine Learning for Sentiment Analysis\n",
    "Today we will learn to build a very simple sentiment predictor, which will allow us to forecast the rating of short product reviews on a scale from very positive (5 stars) to very negative (1 star), based on the content of the text only: we will pretend that we can only see the text, and try if we can predict how many stars the user gave the product based on its tone. This is a useful exercise for situations in which we don't have a \"star rating\" easily available. For example, if we are running our own business, many users will probably write tweets or Facebook posts in which they state their opinion of the business, and we want to be able to quickly sort the good from the bad reviews.\n",
    "\n",
    "For this project, we start by setting up our Python environment, and downloading a couple of example datasets (Amazon product reviews) from the Internet. These data were collected by Julian McAuley, UCSD (http://jmcauley.ucsd.edu/data/amazon/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Apps_for_Android has already been downloaded to ./data/\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "datadir = './data/'\n",
    "\n",
    "import urllib.request, os, gzip\n",
    "\n",
    "## a function to download any amazon products review as given in the dataset collection\n",
    "## if the \"dataset\" contains spaces, replace by underscores \"_\"\n",
    "##BE REALLY AWARE OF THE SPACES, didnt let be work for so long\n",
    "\n",
    "def download_data(dataset_name, datadir):\n",
    "    filename = 'reviews_%s_5.json' % dataset_name\n",
    "    filepath = os.path.join(datadir, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        print(\"Dataset %s has already been downloaded to %s\" % (dataset_name, datadir))\n",
    "    else:\n",
    "        url = 'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/%s.gz' % filename\n",
    "        urllib.request.urlretrieve(url, filepath + \".gz\")\n",
    "        with gzip.open(filepath + \".gz\", 'rb') as fin:\n",
    "            with open(filepath, 'wb') as fout:\n",
    "                fout.write(fin.read())\n",
    "        print(\"Downloaded dataset %s and saved it to %s\" % (dataset_name, datadir))\n",
    "\n",
    "#dataset = \"Beauty\"\n",
    "#download_data(dataset, datadir)\n",
    "dataset = \"Apps_for_Android\"\n",
    "download_data(dataset, datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we use have been stored in the JSON format, which is a standard format for exchanging data over the Internet. The \"JS\" stands for JavaScript, which we'll learn about in week 5 of the summer of code! But Python allows us to read these data using the json library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##reading the data to a variable called data[]\n",
    "import json\n",
    "\n",
    "def load_data(dataset_name,datadir):\n",
    "    filepath = os.path.join(datadir, 'reviews_%s_5.json' % dataset_name)\n",
    "    if not os.path.exists(filepath):\n",
    "        download_data(dataset_name,datadir)\n",
    "    data=[]\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:                   # read file line by line\n",
    "            item_hash = hash(line)       # we will use this later for partitioning our data \n",
    "            item = json.loads(line)      # convert JSON string to Python dict\n",
    "            item['hash'] = item_hash     # add hash for identification purpose\n",
    "            data.append(item)\n",
    "    print(\"Loaded %d data for datasets %s\" % (len(data), dataset_name))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 752937 data for datasets Apps_for_Android\n",
      "{'reviewerID': 'A2RK3QEUEFRNAN', 'asin': 'B008S3EJSU', 'reviewerName': 'Daddy Shawn \"Writer & daddy.\"', 'helpful': [3, 3], 'reviewText': \"Totally worth the $2.99 I paid.  Lots of fun if you're a fan of fantasy RPGs.  And it's a full game, you don't have to keep buying items with real money to continue.  That's refreshing in this horrible age of micro-transactions.  Pick it up.  You do need a good amount of space available on your device, but it's not as bad as the Final Fantasy games.  For those with new Kindles you won't have any problem.  If you've got an older model you may need to clear out some old games that you don't play.\", 'overall': 5.0, 'summary': 'Awesome game & a blast from the past.', 'unixReviewTime': 1395187200, 'reviewTime': '03 19, 2014', 'hash': -782533832592250100}\n"
     ]
    }
   ],
   "source": [
    "# load the data...\n",
    "apps = load_data(dataset, datadir)\n",
    "# ... and have a look at an example item (item number 9426):\n",
    "print(apps[367668])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55851 ...&amp; the losers who gave one star should crawl back into their holes &amp; stay there. What kind of moron gives one star just because they don't do yoga? If I didn't play video games, but got on ign &amp; started throwing out horrible ratings to great games just because I didn't like the looks of them, that would be ridiculous. So is doing it here! Grow up! They give us these apps so we can try them out for free. If it's not for you, move on. If it is, then great. But why would you bash the people giving it to you? Probably because you're pathetic, immature morons, who obviously have no conception of the real world. Or, like the one guy, are a religious fanatic who figures he must give one star to the satanists who made an app like this. Amazon is going to stop the faotd thing if geniuses like you keep giving bad reviews for no reason, &amp; keep complaining that they aren't giving out apps that only you like. They have to give such a huge variety to try to please everyone. People from 7-87 years old have smart phones, &amp; they can't just please one demographic. So, grow up &amp; realize life is not just about you!This app is great btw. If you do yoga, or want to learn, this is a great free way to do so!\n",
      "268244 awesome game played on a friends ipod liked it and saw it was for the the kindle on amazon even though amazon is horrible at getting the good apps. I would highly recommend this game. also if a game doesn't work for ur device, don't give it a bad review!\n",
      "367668 Totally worth the $2.99 I paid.  Lots of fun if you're a fan of fantasy RPGs.  And it's a full game, you don't have to keep buying items with real money to continue.  That's refreshing in this horrible age of micro-transactions.  Pick it up.  You do need a good amount of space available on your device, but it's not as bad as the Final Fantasy games.  For those with new Kindles you won't have any problem.  If you've got an older model you may need to clear out some old games that you don't play.\n",
      "385160 I figured with a walkthrough available I may as well give it a shot.  I'm so glad I finally did!  Yes, it was difficult, but if you keep checking your inventory and really think about how you can use it- if you like this type of game you know what I mean. And, yes, I used the walkthrough.  AND I LOVED IT !!!  EVERY MINUTE OF IT!!! I did so much better than I thought I would after reading the reviews.  I'm really tired of people leaving horrible reviews for games they don't understand.  It's not the game's fault if a person won't read the product description or the reviews.  The reviews, both good and bad, can give you a lot of specifics that can help you decide if it's the right game  for you.'The Haunt'  IS A GREAT GAME! Played perfectly on my Kindle Fire 2nd gen.  I write this as 'The Haunt 2' is downloading.  Can't wait to get into it....\n",
      "479815 When I saw this game it looked dumb and had horrible graphics. I got the game cause I was bored and now I can't stop playing it! The game is really fun but it has bad graphics still. Just because it has bad graphics doesn't mean it isn't fun. The only problem I don't like is that that every month (months are about five to ten minutes on their game) the game makes you pay the stores and you almost go bankrupt sometimes. It's still a fun game to play though because it doesn't require Internet. I do recommend this to people who like to make there own village's on games.\n",
      "533167 i absolutely love the activity of this game.  enjoy word games, but love moving around with the cursor.  HOWEVER,  i do not like...in fact i hate having to 'enable cookies' to try and respond to anything on my Kindle.  AND I HATE having some kind of streaming ad or movie clip or whatever you have attached to this game.  it is horrible that i have to click 'skip' each and every time i finish a single segment of Boggle by having to skip your attached viewing of stuff.  it is bad enough if it is funny....but worse when it is violent in nature and i do not like the tag along items.  if I can get rid of the tag along items, please tell me how to get rid of them.  this game would be complete without any of these distractions.\n",
      "547298 Oftentimes, movie tie-ins like this can turn out bad if not horrible. In the quest to make a quick buck, the marketing muscle can flex out quite a bit of useless garbage. Not in this case, luckily. This is just a good story with good pictures and good voice acting telling a very good children's tale. While I wouldn't blame you if you were skeptical of things like this, I still must recommend that you get this story for your children especially while it is the free app of the day.\n",
      "578990 Okay okay so I love this game for some reason. I usually hate games like this, having to buy other animals and care for them? I hate that, but this game caught my attention. First, it has AMAZING graphics. I couldn't avoid them. No wonder why it says 3D. Most 3D games have horrible graphics. 0-O Second, I love the background music, solo pretty. Third, animal are soooo are adorable!! Couldn't avoid that. Btw solo pretty means it pretty because it is basically playing solo. Now let's get to the bad things.... .-. First, the other app, same one is just like this but it cost like 3.99 or 2'99 Second, I hate having to buy other animals like dogs, cats, birds, horses reptiles. I have ALL the animals except for the birds :/ OMG I want the birds LOL. In my opinion you should get it :) Another GREAT game is My Horse, I'm Holly OpalHeart on My Horse, please friend me if you play it or join the game. It is not multiplayer, well you can go visit a friend's stable, give them gifts and stuff, but you can't ride or anything. You can also do champs and compete I think. Well try it out!! :) friend me too :)!!!!!! =D\n",
      "588168 I wish I had this soooooo bad I only have minecraft its horrible :-(  it sounds awesome tell me what's its like plz\n",
      "647091 I got this game for my Kindle for my grandson, and he plays it almost everything he comes over to my place. The game does not penalize you for getting something wrong, but also will not forward until you get it correct, which in my grandson's case is a good thing, because if he can get a game to make a horrible noise by being wrong that is what he will do. That is not possible in this educational game. You can also choose which of the mini-games you want to access. There is a British accent to the directions but not so bad that you cannit understand what they are asking you to do.\n",
      "659470 I was a lonely, awkward Freshman in high school the first time I ever played a Virtual Villagers game. And I was hooked from the first day! I wouldn't let anyone near the computer since the second I arrived home from school. Such good memories.I was extremely disappointed when I bought a Kindle last Christmas and discovered there wasn't a single version of Virtual Villager available.But I waited and waited and then I came across Virtual Families. It isn't the same, but it sustained me until Virtual Villagers: Origins was finally released.Let me just say, I absolutely LOVE this game. I live, eat, and breathe Virtual Villagers. No other game compares. Not even Sims.There is only one tiny little problem: my golden child is sadistic. I'm not sure if this happens to anyone else, but the golden child in my game throws a party whenever someone dies. Normally, I am able to overlook it, but this time HE WENT TOO FAR.Please listen to my tale of heartbreak.My favorite Villager died today (October 10, 2013). He was a male named Liko. He was with me since the start of the game. There wasn't  anything extraordinary about him, but he was my favorite nonetheless. He was my first ever Master Scientist and when he was about 60 something, the thought struck me that he might be close to dying, so I granted him youth for 50000 science points. (Totally worth it!) Well, he ended up being in his thirties again and all was well in my world. Time passed, now he had turned 75.I exited the game to play something else while my villagers raked in science points and food, and I returned to find him decomposing. I didn't cry like I usually do when my favorite character or player dies, but I won't deny I was sad.Then something horrible happened.As his remains were being carried away by one of his fellow villagers (and possibly daughter, he was quite the ladies man, even at an old age), the golden child decides to &quot;make a party&quot;. The villager that was carrying his remains drops him halfway to the graveyard and starts dancing. I damn near cried at that. My heart BROKE! Yes, his gravestone was there, but his remains were dropped AND LOST FOREVER because that golden child (who looks suspiciously like the killer doll, Chucky) wanted to watch everyone dance.I hate the golden child at this particular moment. HATE him.Golden Child, you have ruined Liko's burial. For that you must pay.I would even go far as saying: &quot;My name is Cindy Herrera. You ruined my Villagers burial. Prepare to die.&quot;But who else will replenish my food? We live in a cruel, cruel world.R.I.P. Liko, Master Scientist, Age 75You were a great person. A not-so-good dad, but an excellent scientist.You will forever live on in my heart.The only good thing is that there is a heart engraved on his headstone. I truly did love Liko and I'm glad the heart is there. It makes me feel as if the others saw i thought fondly of him and engraved a heart to show me they felt the same way... Now every time we look at his grave we'll remember the good times we had with him and how much he meant to us.Take THAT, golden child!Other than that incident, though, this game is a slice of heaven. It isn't perfect, but i love it.I only have one suggestion. The older villagers should be able to tell the younger villagers stories. I started this game thinking that if you dropped an older villager onto a younger one, they would tell them a story like in Virtual Families. Instead, the little ones run away and we get the message &quot;the villager is still too young!&quot; Or something along those lines. I felt like a pervert the first time I read that. That poor little kid must have thought I approached him with bad intentions. I DIDN'T! I simply wanted to tell him a story. Because a life without stories would be truly boring, in my opinion.Like I mentioned before, I've been playing Virtual Villagers since I was a teenager. I've played just about every version and I have yet to be disappointed.Thanks for the great memories, Last Day of Work.May they last forever!\n"
     ]
    }
   ],
   "source": [
    "## good reviews with bad words, these break our machines!!\n",
    "for i, l in enumerate(apps):\n",
    "    if l['overall'] == 5.0 and 'horrible' in l['reviewText'] and 'bad' in l['reviewText'] and l['helpful'][0]>0:\n",
    "        print(i, l['reviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dataset contains 160792 data items, with 9 fields called reviewTime, asin, reviewerID, reviewText, unixReviewTime, summary, helpful, reviewerName, overall. For example, this particular review was written on May 20, 2005, by the user 'Erin White \"Erin\"'. Erin summarized the product as \"Has more comforts than Medela!\" and gave it 5 stars (out of 5). 7 out of 8 other users rated this review helpful. We also added a hash, which is a single number summarizing the whole data item. For now we can view it as a random ID that is (extremely likely to be) unique for each data item, a bit like a US social security number.\n",
    "\n",
    "For this project, we will ignore all fields except reviewText and overall (i.e. the overall rating in stars out of five). The idea is to find out if we can infer the star rating (how much the user liked the product) by only looking at the text. This way we can learn how to automatically analyze even texts that come without a star rating, such as Facebook posts or tweets.\n",
    "\n",
    "Before we start building a complicated AI solution, it is good practice to first implement a very simple \"baseline predictor\" and measure its performance. This way we get a feeling how hard (or easy) the problem is, For example, we can check for the presence of certain words with strong positive or negative connotations, such as \"good\" or \"fantastic\" versus \"bad\" or \"poor\". Note that this review contains the words \"horrible\", \"hurt\", \"bad\" and \"problem\", and still received 5 stars. This gives us already a feeling for the difficulty of the sentiment analysis problem.\n",
    "\n",
    "Before we develop our first sentiment predictor, we need to partition our data into a **training set, a validation set, and a test set**. This is something we should do in all our machine learning projects. The idea is that our predictor might overgeneralize from the examples we show it if we are not careful. This is a bit like a child whom you have shown how an iPad works, and then they try to swipe everything that looks like a screen (the TV, the microwave etc.)\n",
    "\n",
    "For instance, the example review listed above might be the only review with the phrase \"6 hours\" in it, and our predictor might learn a rule that the phrase \"6 hours\" is indicative of a high star rating. Such a rule would be unlikely to generalize well to new reviews that we didn't show to the predictor while it was training. So after training our predictor (using only examples from the training set), we need to be able to measure its performance on reviews it hasn't seen yet, which is what the test set is for. We use the validation set because we may want to explore different predictor variants and get an idea how well they perform on unseen examples before committing to one.\n",
    "\n",
    "Therefore the general procedure when developing a predictor using machine learning is as follows:\n",
    "\n",
    "Train several variants of a predictor using examples from the training set only. Use the predictor performance on the validation set to select a single best predictor among all the possible variants. This step also involves debugging our implementation of the predictor, tweaking its parameters etc. Use the test set to get an idea how well our best predictor is expected to perform on unseen data. This step should only be performed once, at the very end of the experiment: if we tweak our predictor based on its performance on the test set, we simply may find a variant that \"gets lucky\" on the test set, and overestimate its accuracy on truly unseen examples. A common rule of thumb is to use 60% of our data for the training, 20% for validation, and 20% for testing. We could simply take the first 60% of our review data for training, but then we have to assume that the dataset has been \"mixed\" well in advance. We achieve a better randomization by using the hash we computed from the JSON string and checking its modulus 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 451730 training examples, 150797 validation examples, and 150410 test examples\n"
     ]
    }
   ],
   "source": [
    "def partition_train_validation_test(data):\n",
    "    # 60% : modulus is 0, 1, 2, 3, 4, or 5\n",
    "    data_train = [item for item in data if item['hash']%10<=5]  \n",
    "    # 20% : modulus is 6 or 7\n",
    "    data_valid = [item for item in data if item['hash']%10 in [6,7]] \n",
    "    # 20% : modulus is 8 or 9\n",
    "    data_test  = [item for item in data if item['hash']%10 in [8,9]] \n",
    "    return data_train, data_valid, data_test\n",
    "    \n",
    "apps_train, apps_valid, apps_test = partition_train_validation_test(apps)\n",
    "\n",
    "print(\"Now we have\", len(apps_train), \"training examples,\", len(apps_valid),\n",
    "      \"validation examples, and\", len(apps_test), \"test examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction algorithms generally work with numbers instead of text. Therefore we need to preprocess our text by extracting from it numeric **\"features\"** that we can afterwards feed into our predictor. For our simple baseline predictor, we will use only two features: the frequency of positive words in the review (\"good\", \"great\", \"like\") and the frequency of negative words in the review (\"bad\", \"horrible\", \"dislike\"). Let's call these two features **fpos** and **fneg**. Our hypothesis is that reviews with many positive words (high fpos) are likely to receive 4 or 5 stars, while reviews with many negative words (high fneg) will probably receive 1 or 2 stars. Since reviews differ in their length, it makes sense to express the **frequency of positive and negative words as a fraction of the total number of words in the review. Therefore fpos and fneg will be numbers between 0 and 1**.\n",
    "\n",
    "For example, assume the review text is \"This is a good, great, fantastic, amazing, wonderful, super product!\". We count six positive words and zero negative words (out of ten words in total), so fpos == 0.6 (6/10) and fneg == 0.0 (0/10).\n",
    "\n",
    "On the other hand, the review \"This is a bad, atrocious, terrible, dreadful, awful, abysmal product!\" will have fpos == 0.0 (0/10) and fneg == 0.6 (6/10). Alternatively we could decide to discount all **\"stop words\"**: these are extremely common words such as \"this\", \"is\" or \"a\", which are required by the syntax of the English language but don't really carry semantic meaning. If we strip out these three words, we have fpos == 0.857 (6/7) in the first example, and fneg == 0.857 in the second example.\n",
    "\n",
    "Writing down all positive and negative words in the English language by hand would be a very long and tedious task. Thankfully we don't have to do this ourselves, since it was already done by Hu and Liu (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html). The Hu-Liu lexicon of positive and negative opinion words is available as part of NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some positive words: dazzled, colorful, dreamland, thinner, dawn, entrancing, benevolent, champ, hug, supporter\n",
      "Some negative words: plight, irksome, bemused, misrepresentation, discontentedly, stupify, conflicted, sloppy, stinging, reviled\n",
      "Words that appear in both sets: envious, enviousness, enviously\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import opinion_lexicon\n",
    "positive_words = set(opinion_lexicon.positive())\n",
    "negative_words = set(opinion_lexicon.negative())\n",
    "\n",
    "import random\n",
    "random.seed(1234)\n",
    "print(\"Some positive words:\", \", \".join(random.sample(positive_words, 10))) #notice the 'explode' happening, , before each word\n",
    "print(\"Some negative words:\", \", \".join(random.sample(negative_words, 10)))\n",
    "\n",
    "intersection = positive_words & negative_words ## intersection using ONLY '&' WOAH!!\n",
    "print(\"Words that appear in both sets: \" + \", \".join(intersection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While sentiment labeling of individual words can be subjective, most people would agree with the classification as positive or negative for these examples. Notice that the Hu-Liu lexicon contains different word forms: for example, it contains both adjectives (\"wholesome\") and adverbs (\"harshly\"), and verbs appear both in the base form (\"blurt\") and in inflected forms (\"picketing\"). **It also contains common misspellings (\"flicering\" instead of \"flickering\")**. This is why we will take the words in the reviews as they are (apart from minor preprocessing steps such as converting from upper-case to lower-case), and won't apply more sophisticated preprocessing techniques such as stemming.\n",
    "\n",
    "We can now write a function that takes a review text and outputs the number of positive and negative words in the review as a fraction of the total number of words in the review (excluding stop words and punctuation). Note that we have to deal with the **special case when the total number of words is zero**, which happens if the review text is empty. Otherwise we'll end up dividing by zero, and you'll remember from high school that this is not allowed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8571428571428571, 0.0)\n",
      "(0.0, 0.8571428571428571)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "#sent_tokenize() divides a para into sentences and word_tokenize() divides a sentence into words\n",
    "\n",
    "eng_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def my_tokenize(text):\n",
    "    # split text into lower-case tokens, removing all-punctuation tokens and stopwords\n",
    "    tokens = []\n",
    "    for sentence in sent_tokenize(text):\n",
    "        tokens.extend(x for x in word_tokenize(sentence.lower()) \n",
    "                      if x not in eng_stopwords and any(i.isalpha() for i in x)) #any means the word has atleast 1 alphabet\n",
    "    return tokens\n",
    "\n",
    "def pos_neg_fraction(text):\n",
    "    tokens = my_tokenize(text)\n",
    "    count_pos, count_neg = 0, 0\n",
    "    for t in tokens:\n",
    "        if t in positive_words:\n",
    "            count_pos += 1\n",
    "        if t in negative_words:\n",
    "            count_neg += 1\n",
    "    count_all = len(tokens)\n",
    "    if count_all != 0:\n",
    "        return count_pos/count_all, count_neg/count_all ## notice returning a pair\n",
    "    else:\n",
    "        return 0., 0.\n",
    "    \n",
    "pos_example = 'This is a good, great, fantastic, amazing, wonderful, super product!!!'\n",
    "neg_example = 'This is a bad, atrocious, terrible, dreadful, awful, abysmal product!!!'\n",
    "print(pos_neg_fraction(pos_example))\n",
    "print(pos_neg_fraction(neg_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For our two example sentences, this seems to do what we want. Obviously, real reviews usually don't have such an extreme concentration of positive or negative words. Let's find the reviews in our real-world datasets with the highest fraction of positive and negative words, respectively. When exploring the data, it is generally a good idea to restrict ourselves to the training data only, to avoid \"peeking ahead\" and designing our algorithm so that it works well for the test examples we see.\n",
    "\n",
    "For the subsequent analysis, we **convert our training data set into a matrix X_train** with two columns and as many rows as there are examples in the data set. The first column contains the fraction of positive words, while the second column contains the fraction of negative words for each example. numpy.array is the standard way to represent matrices in Python. It provides useful helper functions, such as for finding the maximum in each column.\n",
    "\n",
    "Note that the following cell may take a few minutes to run:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##THIS BLOCK TAKES YEARS TO EXECUTE\n",
    "import numpy\n",
    "\n",
    "def dataset_to_matrix(data):\n",
    "    return numpy.array([list(pos_neg_fraction(item['reviewText'])) for item in data])\n",
    "\n",
    "X_train = dataset_to_matrix(apps_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### loking at the most positive and most negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found a fraction of 100.000000 % positive words for example 1779\n",
      "{'reviewerID': 'A1Q19JB1PE2V5V', 'asin': 'B004DPC5Y2', 'reviewerName': 'Artemis Antoninis', 'helpful': [0, 0], 'reviewText': 'Not fun', 'overall': 1.0, 'summary': 'Bleh', 'unixReviewTime': 1405036800, 'reviewTime': '07 11, 2014', 'hash': -8469365317120483336}\n",
      "We found a fraction of 100.000000 % negative words for example 6576\n",
      "{'reviewerID': 'A1HZYCWWJ53TS5', 'asin': 'B004HE5TAG', 'helpful': [0, 0], 'reviewText': 'boring', 'overall': 2.0, 'summary': 'Two Stars', 'unixReviewTime': 1405382400, 'reviewTime': '07 15, 2014', 'hash': -5041283464654598229}\n"
     ]
    }
   ],
   "source": [
    "most_pos, most_neg = numpy.argmax(X_train, axis=0) #axis=0 means along columns, axis=1 means along rows\n",
    "# print the example with the highest fraction of positive words:\n",
    "print(\"We found a fraction of %f %% positive words for example %d\" % \n",
    "      (100.*X_train[most_pos, 0], most_pos)) ## this means taking the value of id 'most_pos' from the 0th column\n",
    "print(apps_train[most_pos])\n",
    "print(\"We found a fraction of %f %% negative words for example %d\" %\n",
    "      (100.*X_train[most_neg, 1], most_neg)) ## this means taking the value of id 'most_neg' from the 1st column\n",
    "print(apps_train[most_neg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there actually is an example with 100% positive words (excluding stopwords), which received 5 stars, and also an example with 100% negative words, which received 1 star. Our idea of counting positive and negative words seems promising! We are now almost ready to train our first predictor. The only thing left to do is to collect the numbers we want to predict (the star ratings which are called ``overall`` in the JSON data), and put them into another NumPy array. We'll call this one Y_train.\n",
    "\n",
    "In machine learning parlance, **the matrix X_train is called the feature matrix (what we already know) and the matrix Y_train is called the target vector (what we want to predict based on the features)**. You may remember from high-school algebra that vectors are one-dimensional while matrices are two-dimensional. This is because for every example we may have multiple features, but usually a single target. In this case we have two features (fractions of positive and negative examples), so our feature matrix has two columns.\n",
    "\n",
    "Generally, most machine learning algorithms prefer dealing with numbers (matrices) - so we have to find a way to extract numerical information from non-numerical data such as text. This is exactly what we did when counting the fraction of positive and negative words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our feature matrix is two-dimensional and has shape (451730, 2)\n",
      "Our target vector is one-dimensional and has shape (451730,)\n"
     ]
    }
   ],
   "source": [
    "def dataset_to_targets(data):\n",
    "    return numpy.array([item['overall'] for item in data])\n",
    "\n",
    "Y_train = dataset_to_targets(apps_train)\n",
    "print(\"Our feature matrix is two-dimensional and has shape\", X_train.shape)\n",
    "print(\"Our target vector is one-dimensional and has shape\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a real machine learning project, now would be a good time to spend more time exploring and visualizing the data. For example, it is a good idea to get a feeling how the features and targets are distributed, as this determines which techniques are a good fit for the problem. The Python community has created a lot of great tools and libraries for exploratory data analysis - unfortunately we don't have the time to discuss them in detail right now.\n",
    "\n",
    "However, at least we can give you some pointers if you want to study this topic for yourself. We recommend that anyone interested in becoming a data scientist should have a look at the **Pandas** library. For example, if you want to visualize how many 1-star, 2-star etc. ratings there are in the dataset, you can do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a2645638d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas ## pip3 install pandas, this killed my day had to put the \"3\"\n",
    "pandas.Series((Y_train)).value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Aysha Kamal\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\python.exe'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that 5-star review are by far the most frequent, and very few people leave a 1-star review. We can also visualize the distribution of our features. We see that most reviews don't have negative words at all (sharp peak around 0), while reviews without any positive words are much rarer. The typical review seems to contain around 10% positive words, and around 5% negative words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a2621a7518>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#now had to install skipy (pip3 install scipy) -__-\n",
    "df = pandas.DataFrame(data=X_train, columns = ['fpos', 'fneg'])\n",
    "df.plot.kde(xlim=(-0.05, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "These two examples are just meant to whet your appetite. To find out more, have a look at the Pandas documentation (https://pandas.pydata.org/pandas-docs/stable/tutorials.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor\n",
    "We are now ready to train our first predictor! Generally it's a good idea to keep it simple at the beginning, so we'll start with a method you will probably remember from high school: **linear regression** (also known as least-squares regression). If you haven't studied the mathematics before or would like to refresh your memory, there are many good materials on the Internet, e.g. on Khanacademy: https://www.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data Otherwise you can also use the Python libraries as a \"black box\" - this will be sufficient if you don't plan on working with data a lot.\n",
    "\n",
    "Later this week we'll learn how to use Google's Tensorflow library to train a linear regression model: however, that will be mostly for pedagogical purposes, and would be a bit of an overkill in practice. The **Scikit**-learn library (http://scikit-learn.org/stable/) has very good implementations of classical predictors such as linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for the fpos variable is 3.7858833518386943\n",
      "The coefficient for the fneg variable is -3.961652271328679\n",
      "The intercept is 3.5480097262375017\n"
     ]
    }
   ],
   "source": [
    "#DOWNLOAD SKLEARN pip3 install sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lreg = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "print(\"The coefficient for the fpos variable is\", lreg.coef_[0])\n",
    "print(\"The coefficient for the fneg variable is\", lreg.coef_[1])\n",
    "print(\"The intercept is\", lreg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like this, we have trained our first machine learning model! Since linear regression is a very simple predictor, we can actually understand its inner workings quite well. The intercept is the star rating we would expect for a review that contains neither positive nor negative words (fpos==0 and fneg==0): according to the model, such a review should get about 4 stars on average.\n",
    "**y=ax + bx^2 + c , if a=0,b=0, y=c ^^**\n",
    "If the review contains 20% positive words (fpos==0.2) but still no negative words (fneg==0), we would expect the following rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating is 4.305186 stars\n",
      "This is the same as 4.305186 stars\n"
     ]
    }
   ],
   "source": [
    "features = [[0.2, 0]]\n",
    "expected_rating_A = lreg.predict(features)[0]\n",
    "print(\"The expected rating is %f stars\" % expected_rating_A)\n",
    "# we can also compute this explicitly:\n",
    "expected_rating_B = lreg.intercept_ + 0.2*lreg.coef_[0] + 0*lreg.coef_[1]\n",
    "print(\"This is the same as %f stars\" % expected_rating_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if the review contains no positive words (fpos==0) but 20% negative words (fneg==0.2), we expect the following rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating is 2.755679 stars\n",
      "This is the same as 2.755679 stars\n"
     ]
    }
   ],
   "source": [
    "features = [[0, 0.2]]\n",
    "expected_rating_A = lreg.predict(features)[0]\n",
    "print(\"The expected rating is %f stars\" % expected_rating_A)\n",
    "# we can also compute this explicitly:\n",
    "expected_rating_B = lreg.intercept_ + 0 * lreg.coef_[0] + 0.2 * lreg.coef_[1]\n",
    "print(\"This is the same as %f stars\" % expected_rating_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the more positive words we have in our review, the higher the expected star rating (the coefficient for the first variable is positive).\n",
    "\n",
    "The more negative words there are in the review, however, the lower is the expected star rating (the coefficient for the second variable is negative). This is what we would intuitively expect.\n",
    "\n",
    "Remember our two examples from earlier, which contained 100% positive words (\"so cute\") or 100% negative words (\"uncomfortable\"). For these two extreme examples, we get a very odd prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate homework:\n",
    "- calculate the prediction for 100% pos, and 100% neg review\n",
    "- repeat this same process for \"Apps for Android\" dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100% positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating is 7.333893 stars\n",
      "This is the same as 7.333893 stars\n"
     ]
    }
   ],
   "source": [
    "features = [[1, 0]]\n",
    "expected_rating_A = lreg.predict(features)[0]\n",
    "print(\"The expected rating is %f stars\" % expected_rating_A)\n",
    "# we can also compute this explicitly:\n",
    "expected_rating_B = lreg.intercept_ + 1*lreg.coef_[0] + 0*lreg.coef_[1]\n",
    "print(\"This is the same as %f stars\" % expected_rating_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100% negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating is -0.413643 stars\n",
      "This is the same as -0.413643 stars\n"
     ]
    }
   ],
   "source": [
    "features = [[0,1]]\n",
    "expected_rating_A = lreg.predict(features)[0]\n",
    "print(\"The expected rating is %f stars\" % expected_rating_A)\n",
    "# we can also compute this explicitly:\n",
    "expected_rating_B = lreg.intercept_ + 0*lreg.coef_[0] + 1*lreg.coef_[1]\n",
    "print(\"This is the same as %f stars\" % expected_rating_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we haven't told our predictor that all ratings must lie between 1 and 5 stars, it became a bit overenthusiastic in its predictions for these extreme examples. We can simply \"cut off\" these unrealistic results: if the predicted star rating is above 5 stars, we set it to 5 stars, and if it is below 1 star, we set it to 1 star. Now we have a practical prediction algorithm, which we can apply to our training dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make modified corrected predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lreg(features):\n",
    "    expected_rating = lreg.predict(features)\n",
    "    expected_rating[expected_rating > 5.0] = 5.0\n",
    "    expected_rating[expected_rating < 1.0] = 1.0\n",
    "    return expected_rating\n",
    "\n",
    "pred_train = predict_lreg(X_train) ##predicted the whole training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying the extremes again: \n",
    "(max 5 star, min 1 star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_lreg([[1,0]]) #100% pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_lreg([[0,1]]) #100% pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual error checking\n",
    "Let's look at some random examples first to get a feeling how well this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example number 0\n",
      "True rating = 5.000000 stars, expected rating = 4.056277 stars\n",
      "Features = 0.181818 / 0.045455\n",
      "Review text = Oh, how my little grandson loves this app. He's always asking for \"Monkey.\" Grandma has tired of it long before he has. Finding the items on each page that he can touch and activate is endlessly entertaining for him, at least for now. Well worth the $.99.\n",
      "Training example number 10000\n",
      "True rating = 4.000000 stars, expected rating = 4.809971 stars\n",
      "Features = 0.333333 / 0.000000\n",
      "Review text = Good game for the price.  Nice graphics, enjoyable switchable background music, and simple enough gameplay.  Plays well on my A500.\n",
      "Training example number 20000\n",
      "True rating = 5.000000 stars, expected rating = 4.305186 stars\n",
      "Features = 0.200000 / 0.000000\n",
      "Review text = I love playing this game.  Gives my brain a nice workout with words and where to put them for more points.\n",
      "Training example number 30000\n",
      "True rating = 5.000000 stars, expected rating = 4.088850 stars\n",
      "Features = 0.142857 / 0.000000\n",
      "Review text = I listen to old time radio on XM and when I found this, I really liked it. It is simple to navigate and understand. Thank you so much for providing this.\n",
      "Training example number 50000\n",
      "True rating = 5.000000 stars, expected rating = 4.564544 stars\n",
      "Features = 0.363636 / 0.090909\n",
      "Review text = I love this game!!!!!!! I love the fart noises. Don't you? happy mothers' day to all the moms. love this.\n"
     ]
    }
   ],
   "source": [
    "def analyze_training_example(i):\n",
    "    print(\"Training example number\", i)\n",
    "    print(\"True rating = %f stars, expected rating = %f stars\" % (Y_train[i], \n",
    "                                                                  pred_train[i]))\n",
    "    print(\"Features = %f / %f\" % (X_train[i,0], X_train[i,1]))\n",
    "    print(\"Review text = %s\" % apps_train[i]['reviewText'])\n",
    "\n",
    "for i in [0, 10000, 20000, 30000, 50000]: #some random numbers\n",
    "    analyze_training_example(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['miss', 'best']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#trying to see why the predictor predicts 3.538736 star to a 5 star, in number 30000\n",
    "str=\"Have XM radio in the car while driving. Usually miss the ending. But with this I get the whole show while I relaxing and taking a shower..This is the best appI've ever had. Use while waiting for the doc and last week me and the doc listened to Dragnet. He's putting it on his devise too\"\n",
    "\n",
    "def pos_neg_words_show(text):\n",
    "    tokens = my_tokenize(text)\n",
    "    pos=[]\n",
    "    neg=[]\n",
    "    for t in tokens:\n",
    "        if t in positive_words:\n",
    "            pos.append(t)\n",
    "        if t in negative_words:\n",
    "            pos.append(t)\n",
    "    print(pos)\n",
    "    print(neg)\n",
    "\n",
    "pos_neg_words_show(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so looks like the above example simply didnt have enough \"Positive\" words. so \"no negative words\" didnt help improve the rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for baby data set\n",
    "Not terrible, but far from perfect either. These few examples already show some of the limitations of our approach. For example, example 50000 is a 1-star review which contains only a single negative word (\"hangs\"), so the predictor overestimates the rating.\n",
    "\n",
    "Example 20000 likewise overestimates the rating because it counts words like \"top\" and \"fabulous\", which don't refer to the product itself in this example.\n",
    "\n",
    "Example 30000 is not too far off, but it underestimates the rating because it counts \"regret\" as a negative word and overlooks the preceding \"not\". **Sophisticated sentiment analyzers need to account for negation**: for example, \"not bad\" should be treated differently from \"bad\". **Intensifiers** should also be accounted for: in example 10000, \"very disappointed\" is stronger than \"disappointed\", but our predictor doesn't know this.\n",
    "\n",
    "### Auto Error Checking\n",
    "While looking at individual examples is important and instructive, we need a systematic way to measure the prediction quality across all examples. Scikit-learn provides different evaluation metrics. The conceptually easiest choice is the **mean absolute error**, which counts by how many stars our predictions are off on average (in either direction).\n",
    "\n",
    "For example, assume we have three examples with true star ratings of 1, 4, 5, and predicted star ratings of 5, 4, 3. Then the first example is off by 4 stars, the second example by 0 stars (predicted and true rating match exactly), and the third example is off by 2 stars. The mean absolute error is therefore (4 + 0 + 2) / 3 = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error on the training data is 0.989731 stars\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import mean_absolute_error\n",
    "mae_train = mean_absolute_error(pred_train, Y_train)\n",
    "print(\"The mean absolute error on the training data is %f stars\" % mae_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 98.973% ERROR !!! So Useless!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it turns out that we actually aren't that far off, although the accuracy on the validation set is a bit worse than on the training set (which should be expected). Once we move to more complex algorithms, however, we'll have to be very careful not to draw premature conclusions from the training set performance: an algorithm may easily achieve perfect accuracy on the training set, and still completely fail on unseen examples! (Like a student with a photographic memory who can reproduce all the answers to all the math problems she has seen before, but hasn't understood the underlying general theory: so she cannot compute any answer if we change the numbers in the problem slightly).\n",
    "\n",
    "We don't look at the accuracy on the test set yet, because this is the very last step we should do once we are convinced we have found the best predictor we can think of and want to run one final test. For now, we have established that linear regression with the fraction of positive and negative words as features seems to be a reasonable baseline. Can we do better? Stay tuned!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Certification\n",
    "### Beginner - none\n",
    "### Intermediate\n",
    "calculate the prediction for 100% pos, and 100% neg review, before the cutoff\n",
    "repeat this same process for \"Apps for Android\" dataset\n",
    "### Advanced\n",
    "build a better sentiment analyzer and comment both your code and your data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to AI Day 2: Classification versus Regression\n",
    "\n",
    "On day 1, we have tried to forecast a star rating as a number on a continuous scale: star ratings range from 1 to 5, but the way we trained our linear regression model, it sometimes returned a fractional prediction such as 4.37 stars. In general, prediction algorithms that output a number on a continuous scale are called regression algorithms. Linear regression is the most famous member of this family.\n",
    "\n",
    "Sometimes all we really need to know is a **binary answer** to a question: Is a review bad or good? Is a user's comment abusive or not? Does a marketing email convert to a sale or not? Prediction algorithms that output either \"true\" or \"false\" (instead of a number) are called classification algorithms. While classification and regression are similar in many respects, there are also a couple of important differences: both regarding the algorithms we can use and how we evaluate them.\n",
    "\n",
    "For example, assume that the only reviews we are really interested in are those with 1, 2 or 3 stars. Maybe we want to flag dissatisfied customers automatically so that we can review what went wrong and reach out to them. If we don't have the star ratings available for all customers, we want to be able to classify them as either satisfied or dissatisfied based on the textual content of their review alone. Let's introduce a variable **D_train that is true if the customer is dissatisfied **(1, 2 or 3 stars), and false if the customer is satisfied (4 stars or better):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data contains 27.628008 % dissatisfied customers\n",
      "[False False False False False False  True  True False False]\n"
     ]
    }
   ],
   "source": [
    "def  discretize_targets(Y):\n",
    "    return Y<=3.0\n",
    "\n",
    "D_train = discretize_targets(Y_train)\n",
    "print(\"The training data contains %f %% dissatisfied customers\" % (100.*D_train.mean()))\n",
    "print(D_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple classifier would be an algorithm that takes a review text and produces either \"true\" or \"false\" as an output. While this is often already useful, it doesn't tell us how **confident** the classifier is about its predictions. Is the algorithm absolutely sure that the review is bad, or is it a 50-50 decision? We may want to handle these cases differently, since some of the algorithm's errors can be more dangerous than others. In general, a classification algorithm can make two different kinds of errors: **false positives** mean that we wrongly flag a satisfied review (D == false) as dissatisfied, while **false negatives** mean that we wrongly flag a dissatisfied review (D == true) as satisfied. Often we will use our classification algorithm only as a screening filter to flag candidates for manual review. A false positive means that the reviewer has to read a lot of good reviews and confirm that there isn't actually a need to take action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a261fa8f28>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "points = numpy.linspace(-5.0, 5.0)\n",
    "logistic_function = pandas.Series(1/(numpy.exp(-points)+1), index=points)\n",
    "logistic_function.plot()\n",
    "##The underlying way in which logistic function works\n",
    "##Its kinda like a surety vs rating/satisfaction graph, e.g the pc is around\n",
    "##80% sure at 2, 50% sre at arounf 0 etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last time we used linear regression, now we use logistics regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example number 6576\n",
      "True rating = 2.000000 stars\n",
      "Expected to be dissatisfied: True\n",
      "Expected probability of being dissatisfied : 0.996558\n",
      "Features = 0.000000 / 1.000000\n",
      "Review text = boring\n",
      "Training example number 1779\n",
      "True rating = 1.000000 stars\n",
      "Expected to be dissatisfied: False\n",
      "Expected probability of being dissatisfied : 0.000182\n",
      "Features = 1.000000 / 0.000000\n",
      "Review text = Not fun\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression().fit(X_train, D_train)\n",
    "# The predict_proba() method produces a matrix with two columns\n",
    "# the first column contains the probability for the label being \"false\" (satisfied customer)\n",
    "# the second column contains the probability for the label being \"true\" (dissatisfied customer)\n",
    "# the sum of both columns is 1\n",
    "# we select the second column with [:,1]\n",
    "# [:,0] would select the first column\n",
    "# [1,:] would select the second row\n",
    "prob2_train = logreg.predict_proba(X_train)[:,1]\n",
    "pred2_train = prob2_train > 0.5\n",
    "max_prob2 = numpy.argmax(prob2_train)\n",
    "min_prob2 = numpy.argmin(prob2_train)\n",
    "\n",
    "def analyze_training_example_2(i):\n",
    "    print(\"Training example number\", i)\n",
    "    print(\"True rating = %f stars\" % Y_train[i])\n",
    "    print(\"Expected to be dissatisfied:\", pred2_train[i])\n",
    "    print(\"Expected probability of being dissatisfied : %f\" % prob2_train[i])\n",
    "    print(\"Features = %f / %f\" % (X_train[i,0], X_train[i,1]))\n",
    "    print(\"Review text = %s\" % apps_train[i]['reviewText'])\n",
    "    \n",
    "analyze_training_example_2(max_prob2)\n",
    "analyze_training_example_2(min_prob2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Intermediate HW\n",
    "Change the treshold from 0.5 to 0.2, and rerun the code.\n",
    "\n",
    "Give a commentary in plain English about how that changed precision and recall. What does that mean? What is now included that wasn't before? What part of it is good? What is bad from our Task perspective. Remember: our task was to identify Dissatisfied reviews.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example number 6576\n",
      "True rating = 2.000000 stars\n",
      "Expected to be dissatisfied: True\n",
      "Expected probability of being dissatisfied : 0.996558\n",
      "Features = 0.000000 / 1.000000\n",
      "Review text = boring\n",
      "Training example number 1779\n",
      "True rating = 1.000000 stars\n",
      "Expected to be dissatisfied: False\n",
      "Expected probability of being dissatisfied : 0.000182\n",
      "Features = 1.000000 / 0.000000\n",
      "Review text = Not fun\n"
     ]
    }
   ],
   "source": [
    "##Change the treshold from 0.5 to 0.2, and rerun the code.\n",
    "pred2A_train = prob2_train > 0.2\n",
    "\n",
    "def analyze_training_example_2A(i):\n",
    "    print(\"Training example number\", i)\n",
    "    print(\"True rating = %f stars\" % Y_train[i])\n",
    "    print(\"Expected to be dissatisfied:\", pred2A_train[i])\n",
    "    print(\"Expected probability of being dissatisfied : %f\" % prob2_train[i])\n",
    "    print(\"Features = %f / %f\" % (X_train[i,0], X_train[i,1]))\n",
    "    print(\"Review text = %s\" % apps_train[i]['reviewText'])\n",
    "    \n",
    "analyze_training_example_2A(max_prob2)\n",
    "analyze_training_example_2A(min_prob2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW text\n",
    "Precision reduced and recall increased! Whenever there is more than 20% probability that the review might be bad, we are flagging it, 20% is a small number honestly to flag a review. On the otherhand, the more we are trying to help people and manually check reviews(even with 80% good probability to be a good review), the more time consuming human work has to be done. So the power of machine learning and automation isn't used to it's potential. It might be good that we are certainly getting most bad reviews and checking them, so that there are no loopholes, but from task perspective the bad part is the reduced automation of flagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the default threshold (0.5) we get precision = 0.652288 and recall = 0.229239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision2 = precision_score(D_train, pred2_train)\n",
    "recall2 = recall_score(D_train, pred2_train)\n",
    "print(\"For the default threshold (0.5) we get precision = %f \"\n",
    "      \"and recall = %f\" % (precision2, recall2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/330px-Precisionrecall.svg.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We only found 22% of the dissatisfied customers, missed 78% of dissatisfied customers(false negatives).\n",
    "#### Out of the ones we flagged, 65% are actually dissatified, 35% are actually okay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW precision recall check (verify with text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the default threshold (0.2) we get precision = 0.372425 and recall = 0.840454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision2A = precision_score(D_train, pred2A_train)\n",
    "recall2A = recall_score(D_train, pred2A_train)\n",
    "print(\"For the default threshold (0.2) we get precision = %f \"\n",
    "      \"and recall = %f\" % (precision2A, recall2A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision REDUCED from 65% to 37% \n",
    "## Recall increased from 22% to 84%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision as function of threshold:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a26210ab00>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "all_precision2, all_recall2, all_thresh2 = precision_recall_curve(\n",
    "    D_train, prob2_train)\n",
    "print(\"Precision as function of threshold:\")\n",
    "pandas.Series(all_precision2[:-1], index=all_thresh2).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall as function of threshold:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a262554da0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Recall as function of threshold:\")\n",
    "pandas.Series(all_recall2[:-1], index=all_thresh2).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall as function of precision:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a2626050f0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## A trade-off graph, precision vs recall trade-off\n",
    "print(\"Recall as function of precision:\")\n",
    "pandas.Series(all_recall2[:-1], index=all_precision2[:-1]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details in the book, here we use it as a Black-Box\n",
    "watch the precision-recall improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the precision is 0.565166 and the recall is 0.212573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a2627f9b00>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "nb = GaussianNB().fit(X_train, D_train)\n",
    "prob3_train = nb.predict_proba(X_train)[:,1]\n",
    "pred3_train = prob3_train>0.5\n",
    "precision3 = precision_score(D_train, pred3_train)\n",
    "recall3 = recall_score(D_train, pred3_train)\n",
    "print(\"Now the precision is %f and the recall is %f\" % (precision3, recall3))\n",
    "all_precision3, all_recall3, all_thresh3 = precision_recall_curve(\n",
    "    D_train, prob3_train)\n",
    "pandas.Series(all_recall3[:-1], index=all_precision3[:-1]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 6 of NLTK describes Naive-Bayes http://www.nltk.org/book/ch06.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.6\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow\n",
    "Linear Regression\n",
    "\n",
    "Step 1: Make sure you follow installation guide of TensorFlow and then you will be able to import it. https://www.tensorflow.org/\n",
    "<br/> `N.B: Tensor flow supports only 3.5 and 3.6 python, higher versions wont work as well.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\AYSHAK~1\\AppData\\Local\\Temp\\tmpdkby2j2p\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\AYSHAK~1\\\\AppData\\\\Local\\\\Temp\\\\tmpdkby2j2p', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002A2620BA630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\AYSHAK~1\\AppData\\Local\\Temp\\tmpdkby2j2p\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2459.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 401.736\n",
      "INFO:tensorflow:loss = 307.25983, step = 101 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 518.303\n",
      "INFO:tensorflow:loss = 224.19489, step = 201 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 558.836\n",
      "INFO:tensorflow:loss = 257.6741, step = 301 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 545.101\n",
      "INFO:tensorflow:loss = 249.53754, step = 401 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.777\n",
      "INFO:tensorflow:loss = 162.67355, step = 501 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.214\n",
      "INFO:tensorflow:loss = 217.49388, step = 601 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.672\n",
      "INFO:tensorflow:loss = 186.04355, step = 701 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.485\n",
      "INFO:tensorflow:loss = 278.78156, step = 801 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.127\n",
      "INFO:tensorflow:loss = 146.59091, step = 901 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 567.635\n",
      "INFO:tensorflow:loss = 210.84915, step = 1001 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 607.336\n",
      "INFO:tensorflow:loss = 183.16315, step = 1101 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 591.329\n",
      "INFO:tensorflow:loss = 223.67432, step = 1201 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 573.215\n",
      "INFO:tensorflow:loss = 254.59712, step = 1301 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.158\n",
      "INFO:tensorflow:loss = 185.19913, step = 1401 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.674\n",
      "INFO:tensorflow:loss = 194.9124, step = 1501 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.108\n",
      "INFO:tensorflow:loss = 262.15372, step = 1601 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.28\n",
      "INFO:tensorflow:loss = 143.47293, step = 1701 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.862\n",
      "INFO:tensorflow:loss = 175.17865, step = 1801 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.955\n",
      "INFO:tensorflow:loss = 272.0699, step = 1901 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 702.578\n",
      "INFO:tensorflow:loss = 208.36761, step = 2001 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 706.233\n",
      "INFO:tensorflow:loss = 189.00308, step = 2101 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.135\n",
      "INFO:tensorflow:loss = 233.43733, step = 2201 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.795\n",
      "INFO:tensorflow:loss = 139.3414, step = 2301 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 738.91\n",
      "INFO:tensorflow:loss = 178.89554, step = 2401 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.18\n",
      "INFO:tensorflow:loss = 163.83627, step = 2501 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 687.867\n",
      "INFO:tensorflow:loss = 196.78864, step = 2601 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 747.264\n",
      "INFO:tensorflow:loss = 277.52094, step = 2701 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 715.891\n",
      "INFO:tensorflow:loss = 170.13611, step = 2801 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.468\n",
      "INFO:tensorflow:loss = 230.51779, step = 2901 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 734.069\n",
      "INFO:tensorflow:loss = 187.28664, step = 3001 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.185\n",
      "INFO:tensorflow:loss = 175.22867, step = 3101 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 720.12\n",
      "INFO:tensorflow:loss = 169.82529, step = 3201 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 727.83\n",
      "INFO:tensorflow:loss = 217.08655, step = 3301 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 703.032\n",
      "INFO:tensorflow:loss = 192.68002, step = 3401 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.877\n",
      "INFO:tensorflow:loss = 224.67203, step = 3501 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.609\n",
      "INFO:tensorflow:loss = 255.65747, step = 3601 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 581.579\n",
      "INFO:tensorflow:loss = 177.01212, step = 3701 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.654\n",
      "INFO:tensorflow:loss = 204.85016, step = 3801 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 549.628\n",
      "INFO:tensorflow:loss = 199.30551, step = 3901 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.429\n",
      "INFO:tensorflow:loss = 225.63733, step = 4001 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 568.361\n",
      "INFO:tensorflow:loss = 197.45015, step = 4101 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.248\n",
      "INFO:tensorflow:loss = 169.69214, step = 4201 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 546.623\n",
      "INFO:tensorflow:loss = 229.14194, step = 4301 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.672\n",
      "INFO:tensorflow:loss = 234.20258, step = 4401 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.273\n",
      "INFO:tensorflow:loss = 228.84518, step = 4501 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.015\n",
      "INFO:tensorflow:loss = 163.46243, step = 4601 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 591.908\n",
      "INFO:tensorflow:loss = 188.54884, step = 4701 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.251\n",
      "INFO:tensorflow:loss = 182.9428, step = 4801 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.434\n",
      "INFO:tensorflow:loss = 203.05127, step = 4901 (0.170 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\AYSHAK~1\\AppData\\Local\\Temp\\tmpdkby2j2p\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 130.38425.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x2a264beacf8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "feat_cols = [tf.feature_column.numeric_column(key=\"fpos\"),\n",
    "             tf.feature_column.numeric_column(key=\"fneg\")]\n",
    "model = tf.estimator.LinearRegressor(feature_columns=feat_cols)\n",
    "get_training_data = tf.estimator.inputs.numpy_input_fn(\n",
    "                     x={\"fpos\" : X_train[:,0], \"fneg\" : X_train[:,1]},\n",
    "                     y=Y_train, num_epochs=None, shuffle=True)\n",
    "\n",
    "model.train(input_fn=get_training_data, steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tensor flow was given the fraction of pos and negative words, it spit out tits estimation. \n",
    "Tensor flow was refining and fitting the curve better and better at each step, to compare with the our first model(of linear regression) we find the mean absolute error(auto) / look at absolute values of the predictor(manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\AYSHAK~1\\AppData\\Local\\Temp\\tmpdkby2j2p\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "The mean absolute error on the training data is 1.005123 stars\n"
     ]
    }
   ],
   "source": [
    "eval_training_data = tf.estimator.inputs.numpy_input_fn(\n",
    "                     x={\"fpos\":X_train[:,0], \"fneg\": X_train[:,1]},\n",
    "                     num_epochs=1, shuffle=False)\n",
    "pred_train_tf = numpy.array([item['predictions'][0] for item in \n",
    "                         model.predict(input_fn=eval_training_data)])\n",
    "mae_train_tf = mean_absolute_error(pred_train_tf, Y_train)\n",
    "print(\"The mean absolute error on the training data is %f stars\" \n",
    "      % mae_train_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous absolute error: 98.93%\n",
    "## With TensorFlow: error : 100.5123%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Built In Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking error of the first linear regression, with negation detection included!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence = This product wasn't bad.\n",
      "['this', 'product', 'was', \"n't\", 'bad_NEG', '.']\n",
      "Sentence = This is not a bad product.\n",
      "['this', 'is', 'not', 'a_NEG', 'bad_NEG', 'product_NEG', '.']\n",
      "Sentence = This product was bad.\n",
      "['this', 'product', 'was', 'bad', '.']\n",
      "Sentence = This is a bad product.\n",
      "['this', 'is', 'a', 'bad', 'product', '.']\n"
     ]
    }
   ],
   "source": [
    "##Negation detector : added feature, will it give us better prediction?\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import mark_negation\n",
    "examples_negation = [\"This product wasn't bad.\",\n",
    "                     \"This is not a bad product.\",\n",
    "                     \"This product was bad.\",\n",
    "                     \"This is a bad product.\"]\n",
    "\n",
    "for sentence in examples_negation:\n",
    "    tokens_with_negation = mark_negation(word_tokenize(sentence.lower()))\n",
    "    print(\"Sentence =\", sentence)\n",
    "    print(tokens_with_negation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts out pretty easy, but doesn't take long before you have &#34;hung&#34; yourself.  Some of the words they are looking for are quite long. I am pretty good at word games, but this one is a challege!  On a lower challenge level, pretty easy to win.\n",
      "['starts', 'pretty', 'easy', \"n't\", 'take_NEG', 'long_NEG', 'hung_NEG', 'words', 'looking', 'quite', 'long', 'pretty', 'good', 'word', 'games', 'one', 'challege', 'lower', 'challenge', 'level', 'pretty', 'easy', 'win']\n"
     ]
    }
   ],
   "source": [
    "#all stopwords=eng_stop words + NEG_ version of all eng_stopwords\n",
    "negated_stopwords = set(x+\"_NEG\" for x in eng_stopwords)\n",
    "all_stopwords = eng_stopwords.union(negated_stopwords)        # set union\n",
    "    \n",
    "def tokenize_with_negation(text):\n",
    "    # split text into lower-case tokens, removing all-punctuation tokens and stopwords\n",
    "    tokens = []\n",
    "    for sentence in sent_tokenize(text):\n",
    "        pretokens = word_tokenize(sentence.lower())\n",
    "        pretokens = [x for x in pretokens if any(i.isalpha() for i in x)]\n",
    "        pretokens = mark_negation(pretokens)\n",
    "        tokens.extend(x for x in pretokens if x not in all_stopwords)\n",
    "    return tokens\n",
    "\n",
    "##example of tokening with negation:\n",
    "\n",
    "print(apps_train[5000]['reviewText'])\n",
    "print(tokenize_with_negation(apps_train[5000]['reviewText']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training again with negation included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8571428571428571, 0.0)\n",
      "(0.0, 0.8571428571428571)\n"
     ]
    }
   ],
   "source": [
    "## neagtion of negative words is negative\n",
    "## neagtion of negative words is negative\n",
    "all_positive_words = positive_words.union({x+\"_NEG\" for x in negative_words})\n",
    "all_negative_words = negative_words.union({x+\"_NEG\" for x in positive_words})\n",
    "\n",
    "def pos_neg_fraction_with_negation(text):\n",
    "    tokens = tokenize_with_negation(text)\n",
    "    # count how many positive and negative words occur in the text\n",
    "    count_pos, count_neg = 0, 0\n",
    "    for t in tokens:\n",
    "        if t in all_positive_words:\n",
    "            count_pos += 1\n",
    "        if t in all_negative_words:\n",
    "            count_neg += 1\n",
    "    count_all = len(tokens)\n",
    "    if count_all != 0:\n",
    "        return count_pos/count_all, count_neg/count_all\n",
    "    else:  # avoid division by zero\n",
    "        return 0., 0.\n",
    "    \n",
    "pos_example = 'This is a good, great, fantastic, amazing, wonderful, super product!!!'\n",
    "neg_example = 'This is a bad, atrocious, terrible, dreadful, awful, abysmal product!!!'\n",
    "print(pos_neg_fraction_with_negation(pos_example))\n",
    "print(pos_neg_fraction_with_negation(neg_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.8571428571428571)\n",
      "(0.8571428571428571, 0.0)\n"
     ]
    }
   ],
   "source": [
    "pos_example_neg = 'This is not a good, great, fantastic, amazing, wonderful, super product!!!'\n",
    "neg_example_neg = 'This is not a bad, atrocious, terrible, dreadful, awful, abysmal product!!!'\n",
    "print(pos_neg_fraction_with_negation(pos_example_neg))\n",
    "print(pos_neg_fraction_with_negation(neg_example_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### as we can see above, the neagtion was picked up, and even though positive words were used, they were neagative meaning and so they went on to the 'fneg' side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ALSO TAKES YEARS TO RUN\n",
    "def dataset_to_matrix_with_neg(data):\n",
    "    return numpy.array([list(pos_neg_fraction_with_negation(item['reviewText'])) for item in data])\n",
    "\n",
    "X_train_neg = dataset_to_matrix_with_neg(apps_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the mean absolute error on the training data is 0.972192 stars\n"
     ]
    }
   ],
   "source": [
    "lreg_neg = LinearRegression().fit(X_train_neg, Y_train)\n",
    "pred_train_neg = lreg_neg.predict(X_train_neg)\n",
    "mae_train_with_neg = mean_absolute_error(pred_train_neg, Y_train)\n",
    "print(\"Now the mean absolute error on the training data is %f stars\" % mae_train_with_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error has reduced from 98.97% to 97.22% Great!! Still Worse :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest - NLTK blackbox\n",
    "Donno how it works, it works is all I know, its and nltk's built in predictor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on X_traing_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A nonlinear regressor achieves a MAE of 0.915068 stars\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_neg = RandomForestRegressor().fit(X_train_neg, Y_train)\n",
    "pred_train_rf_neg = rf_neg.predict(X_train_neg)\n",
    "mae_train_rf_neg = mean_absolute_error(pred_train_rf_neg, Y_train)\n",
    "print(\"A nonlinear regressor achieves a MAE of %f stars\" % mae_train_rf_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error reduced from 97.22% to 91.5% ???!!! Amazing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on X_train (original data, no negation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A nonlinear regressor achieves a MAE of 0.946836 stars\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor().fit(X_train, Y_train)\n",
    "pred_train_rf = rf.predict(X_train)\n",
    "mae_train_rf = mean_absolute_error(pred_train_rf, Y_train)\n",
    "print(\"A nonlinear regressor achieves a MAE of %f stars\" % mae_train_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error reduced from 98.87% to 94.68% ???!!! Really reduced a lot !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we did a lot of linear regression and prediction, how to they compare?which has been the worst? which is the best. For sentiment analysis using ONLY POS & NEG word percentage!\n",
    "# *Best so far?* TF < original LR < Negated LR < original with RF < negated RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short-List Promising Models\n",
    "Notes:\n",
    "\n",
    "**If the data is huge, you may want to sample smaller training sets so you can train many different models in a reasonable time** (be aware that this penalizes complex models such as large neural nets or Random Forests). Once again, try to automate these steps as much as possible.\n",
    "\n",
    "1. Train many quick and dirty models from different categories (e.g., linear, naive Bayes, SVM, Random Forests, neural net, etc.) using standard parameters.\n",
    "2. Measure and compare their performance. For each model, use **N-fold cross-validation** (not taught) and compute the mean and standard deviation of the performance measure on the N folds.\n",
    "3. Analyze the most significant variables for each algorithm.\n",
    "4. Analyze the types of errors the models make. What data would a human have used to avoid these errors?\n",
    "5. Have a quick round of feature selection and engineering.\n",
    "6. Have one or two more quick iterations of the five previous steps.\n",
    "7. Short-list the top three to five most promising models, preferring models that make different types of errors.\n",
    "\n",
    "**Source: p. 646. Hands-on Machine Learning** - Application perspective.\n",
    "\n",
    "### Advanced Homework\n",
    "* Add features\n",
    "* Explain which features you chose, implement them, and write a commentary on your results\n",
    "* Feel welcome to use NLTK's built-in sentiment analyzer or any other research that you can find and understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to AI: Week 4 Day 3 \n",
    "### Improvement of Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5209\n",
      "{'reviewerID': 'A1X1CEGHTHMBL1', 'asin': 'B004GMP53U', 'reviewerName': 'jjceo', 'helpful': [0, 0], 'reviewText': \"Posted at 8:53 AMGame Play:The game is very similar to the old Pacman game even to the point where you have a thumb joystick to move your action figure to run the maze and collect the dots. For me unfortunately the joystick is on the LH side of the game and I am right handed so the game is played with my most uncoordinated hand. There is a pause button on the top of the LH side of the screen.The controls take time to get used to and it is difficult at best in an open room to move the character to where you want it to go. You will find that for precise movements you must tap the joystick on the side of the direction you want to move in and it will move in one space increments. It is difficult to try to move precisely while trying to clear the maze and have multiple enemies fluidly coming after you while you struggle to get one colored dot. You have slid your thumb off of the area of the control you want to use and you move in the wrong direction. On my Kindle Fire a calibration screen said it was going to pop up but it never did. I could never find the calibrations screen again.There are dialogs that pop up on the screen while you are playing and the stop the game while you have to read the messages either from the yellow box or the leader of the characters chasing you. I find this to be distracting and not needed and you can turn them off in the options menu.When you get to a certain point in some levels you are playing you will unlock the red squares that chase you. In some rooms there are yellow boxes that you can push in front of the doors so that they cannot enter the room to get you. In other levels you are immediately trapped and you can get stung by one or two of the squares before you can even move. There are open square boxes in the wall of the maze and you can go into one of them and hide and they cannot see you. You can also push the yellow boxes and crush the red squares chasing you. In some levels later in the game there are so many red squares after you that you have virtually nowhere to run.Home Screen:* Start* Scores - takes you to their leaderboard* Options - adjust music, sounds, dialogs off/on and vibrations off/on* About - links to the web and social networkso Visit us - didn't work, it could not find their website.o Follow us on Twittero Become our fan on Facebook.What I like:A remake of the old Pacman games brings back old memories of a fun game. Unfortunately the controls are difficult to use and can be frustrating to find the right touch. I got to be OK at the game after a while but the main limiting factor with the game is the awkwardness of the controls. You may be better at it that I am.What I dislike:The controls of the game on my Kindle Fire are nothing but frustrating to try to use. You are trying to use a joystick to move through a maze while being chased by multiple red squares that are moving with fluid motion while you are struggling to change directions or to pick up a colored dot. It is difficult to make fine adjustments in your position until you get a better feel for the controls. The dot that is the joystick does allow you to make single block steps but while you are trying to get it to work you are being pursued by multiple red squares trying to kill you. It is just awkward.I turned off the popup messages that occur in the middle of the game as I found them distracting and not of value to the game play.I don't like the access to Facebook, Twitter and to the internet to their website. Connections to Facebook allow you to sign in via Facebook so you can challenge and compete against your friends without ever leaving the game. You can invite your friends by posting a link to your Facebook wall. View a list of your Facebook friends who play EVAC HD. Compare your high scores with those of friends on your leaderboard. You can even share your in-game achievements on your wall.The access permissions to the internet are for social networks and for access to the developer's web site. It could have been easily left out as it is unnecessary for those options to be in the app for me.The original Pacman had better graphics and was a lot more fun to play than this game. To compare this game to a classic is an insult to Pacman. This is a cheap knock off with poor graphics and extremely bad controls. This is another example of a developer trying to make money by copying someone else's game concept.Summary:I didn't enjoy this game at all. The poor controls take away from any possibility of enjoying the game play. You are not able to move your character fast enough to evade the many enemies you are facing and you get overwhelmed. The maze also contains a lot of hallways with one box and with one dot in it that forces you to stop, change direction, get the dot, reverse, stop, and change direction, all while being pursued by killer squares.With the present control concept and performance this game is not worth $1.99 and it should be free all the time.Size: 13.54MB uncompressed on my Kindle Fire.Permissions:* Network communication - full internet access* Storage - modify/delete internal storage contents* Network control - view network state, view WIFI state* Hardware controls - control vibrator\", 'overall': 1.0, 'summary': 'Poor controls make this game play not enjoyable, an insult to the Pacman game!', 'unixReviewTime': 1348444800, 'reviewTime': '09 24, 2012', 'hash': -2065613227773481915}\n"
     ]
    }
   ],
   "source": [
    "## checking presence of data\n",
    "##lets find the longest review in training set\n",
    "def find_longest_review(data_given):\n",
    "    mx=0\n",
    "    ret=0;\n",
    "    for i in apps_train:\n",
    "        length=len(i['reviewText'])\n",
    "        if length>5000:\n",
    "            mx=length\n",
    "            ret=i\n",
    "            break\n",
    "    print(mx)\n",
    "    return ret\n",
    "            \n",
    "review_long=find_longest_review(apps_train)\n",
    "print(review_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts out pretty easy, but doesn't take long before you have &#34;hung&#34; yourself.  Some of the words they are looking for are quite long. I am pretty good at word games, but this one is a challege!  On a lower challenge level, pretty easy to win.\n"
     ]
    }
   ],
   "source": [
    "## random data\n",
    "print(apps_train[5000]['reviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK built in sentiment analyzer\n",
    "\n",
    "google nltk vader, \n",
    "http://www.nltk.org/howto/sentiment.html\n",
    "analyzes MANY aspect and tells us , foe each sentence, how positivw, negtive anf neutral it is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posted at 8:53 AMGame Play:The game is very similar to the old Pacman game even to the point where you have a thumb joystick to move your action figure to run the maze and collect the dots.\n",
      "{'neg': 0.0, 'neu': 0.954, 'pos': 0.046, 'compound': 0.1779}\n",
      "For me unfortunately the joystick is on the LH side of the game and I am right handed so the game is played with my most uncoordinated hand.\n",
      "{'neg': 0.073, 'neu': 0.697, 'pos': 0.23, 'compound': 0.6344}\n",
      "There is a pause button on the top of the LH side of the screen.The controls take time to get used to and it is difficult at best in an open room to move the character to where you want it to go.\n",
      "{'neg': 0.052, 'neu': 0.795, 'pos': 0.153, 'compound': 0.5859}\n",
      "You will find that for precise movements you must tap the joystick on the side of the direction you want to move in and it will move in one space increments.\n",
      "{'neg': 0.0, 'neu': 0.906, 'pos': 0.094, 'compound': 0.25}\n",
      "It is difficult to try to move precisely while trying to clear the maze and have multiple enemies fluidly coming after you while you struggle to get one colored dot.\n",
      "{'neg': 0.219, 'neu': 0.71, 'pos': 0.071, 'compound': -0.6597}\n",
      "You have slid your thumb off of the area of the control you want to use and you move in the wrong direction.\n",
      "{'neg': 0.122, 'neu': 0.827, 'pos': 0.051, 'compound': -0.4215}\n",
      "On my Kindle Fire a calibration screen said it was going to pop up but it never did.\n",
      "{'neg': 0.096, 'neu': 0.904, 'pos': 0.0, 'compound': -0.1779}\n",
      "I could never find the calibrations screen again.There are dialogs that pop up on the screen while you are playing and the stop the game while you have to read the messages either from the yellow box or the leader of the characters chasing you.\n",
      "{'neg': 0.048, 'neu': 0.913, 'pos': 0.039, 'compound': -0.1027}\n",
      "I find this to be distracting and not needed and you can turn them off in the options menu.When you get to a certain point in some levels you are playing you will unlock the red squares that chase you.\n",
      "{'neg': 0.054, 'neu': 0.852, 'pos': 0.095, 'compound': 0.1779}\n",
      "In some rooms there are yellow boxes that you can push in front of the doors so that they cannot enter the room to get you.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "In other levels you are immediately trapped and you can get stung by one or two of the squares before you can even move.\n",
      "{'neg': 0.129, 'neu': 0.871, 'pos': 0.0, 'compound': -0.5267}\n",
      "There are open square boxes in the wall of the maze and you can go into one of them and hide and they cannot see you.\n",
      "{'neg': 0.064, 'neu': 0.936, 'pos': 0.0, 'compound': -0.1779}\n",
      "You can also push the yellow boxes and crush the red squares chasing you.\n",
      "{'neg': 0.11, 'neu': 0.89, 'pos': 0.0, 'compound': -0.1531}\n",
      "In some levels later in the game there are so many red squares after you that you have virtually nowhere to run.Home Screen:* Start* Scores - takes you to their leaderboard* Options - adjust music, sounds, dialogs off/on and vibrations off/on* About - links to the web and social networkso Visit us - didn't work, it could not find their website.o Follow us on Twittero Become our fan on Facebook.What I like:A remake of the old Pacman games brings back old memories of a fun game.\n",
      "{'neg': 0.0, 'neu': 0.933, 'pos': 0.067, 'compound': 0.6808}\n",
      "Unfortunately the controls are difficult to use and can be frustrating to find the right touch.\n",
      "{'neg': 0.375, 'neu': 0.625, 'pos': 0.0, 'compound': -0.7783}\n",
      "I got to be OK at the game after a while but the main limiting factor with the game is the awkwardness of the controls.\n",
      "{'neg': 0.082, 'neu': 0.839, 'pos': 0.079, 'compound': -0.0216}\n",
      "You may be better at it that I am.What I dislike:The controls of the game on my Kindle Fire are nothing but frustrating to try to use.\n",
      "{'neg': 0.059, 'neu': 0.765, 'pos': 0.176, 'compound': 0.5202}\n",
      "You are trying to use a joystick to move through a maze while being chased by multiple red squares that are moving with fluid motion while you are struggling to change directions or to pick up a colored dot.\n",
      "{'neg': 0.073, 'neu': 0.883, 'pos': 0.044, 'compound': -0.2732}\n",
      "It is difficult to make fine adjustments in your position until you get a better feel for the controls.\n",
      "{'neg': 0.113, 'neu': 0.676, 'pos': 0.212, 'compound': 0.296}\n",
      "The dot that is the joystick does allow you to make single block steps but while you are trying to get it to work you are being pursued by multiple red squares trying to kill you.\n",
      "{'neg': 0.196, 'neu': 0.739, 'pos': 0.065, 'compound': -0.8271}\n",
      "It is just awkward.I turned off the popup messages that occur in the middle of the game as I found them distracting and not of value to the game play.I don't like the access to Facebook, Twitter and to the internet to their website.\n",
      "{'neg': 0.137, 'neu': 0.863, 'pos': 0.0, 'compound': -0.6537}\n",
      "Connections to Facebook allow you to sign in via Facebook so you can challenge and compete against your friends without ever leaving the game.\n",
      "{'neg': 0.0, 'neu': 0.762, 'pos': 0.238, 'compound': 0.6771}\n",
      "You can invite your friends by posting a link to your Facebook wall.\n",
      "{'neg': 0.0, 'neu': 0.68, 'pos': 0.32, 'compound': 0.5719}\n",
      "View a list of your Facebook friends who play EVAC HD.\n",
      "{'neg': 0.0, 'neu': 0.593, 'pos': 0.407, 'compound': 0.6705}\n",
      "Compare your high scores with those of friends on your leaderboard.\n",
      "{'neg': 0.0, 'neu': 0.763, 'pos': 0.237, 'compound': 0.4767}\n",
      "You can even share your in-game achievements on your wall.The access permissions to the internet are for social networks and for access to the developer's web site.\n",
      "{'neg': 0.0, 'neu': 0.922, 'pos': 0.078, 'compound': 0.296}\n",
      "It could have been easily left out as it is unnecessary for those options to be in the app for me.The original Pacman had better graphics and was a lot more fun to play than this game.\n",
      "{'neg': 0.0, 'neu': 0.691, 'pos': 0.309, 'compound': 0.9162}\n",
      "To compare this game to a classic is an insult to Pacman.\n",
      "{'neg': 0.248, 'neu': 0.752, 'pos': 0.0, 'compound': -0.5106}\n",
      "This is a cheap knock off with poor graphics and extremely bad controls.\n",
      "{'neg': 0.408, 'neu': 0.592, 'pos': 0.0, 'compound': -0.7841}\n",
      "This is another example of a developer trying to make money by copying someone else's game concept.Summary:I didn't enjoy this game at all.\n",
      "{'neg': 0.111, 'neu': 0.889, 'pos': 0.0, 'compound': -0.3875}\n",
      "The poor controls take away from any possibility of enjoying the game play.\n",
      "{'neg': 0.164, 'neu': 0.529, 'pos': 0.307, 'compound': 0.4019}\n",
      "You are not able to move your character fast enough to evade the many enemies you are facing and you get overwhelmed.\n",
      "{'neg': 0.131, 'neu': 0.82, 'pos': 0.049, 'compound': -0.4588}\n",
      "The maze also contains a lot of hallways with one box and with one dot in it that forces you to stop, change direction, get the dot, reverse, stop, and change direction, all while being pursued by killer squares.With the present control concept and performance this game is not worth $1.99 and it should be free all the time.Size: 13.54MB uncompressed on my Kindle Fire.Permissions:* Network communication - full internet access* Storage - modify/delete internal storage contents* Network control - view network state, view WIFI state* Hardware controls - control vibrator\n",
      "{'neg': 0.11, 'neu': 0.856, 'pos': 0.035, 'compound': -0.7241}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "text = review_long['reviewText']  #a review longer than 5000 words, we picked up\n",
    "for s in sent_tokenize(text):\n",
    "    print(s)\n",
    "    print(sia.polarity_scores(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`So vader did quite a good job really, of picking up the tone of each of the sentences`\n",
    "\n",
    "Now we will extract information from here and perform prdiction;\n",
    "6 features from here, also we will keep the previous fpos and fneg features and a length feature, making a total of 9 features. Also added the percent of exclamation sign, so 10 features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALSO WILL TAKE YEARS TO RUN\n",
    "def sia_features(dataset):\n",
    "    \"\"\"For each review text in the dataset, extract:\n",
    "       (1) the mean positive sentiment over all sentences\n",
    "       (2) the mean neutral sentiment over all sentences\n",
    "       (3) the mean negative sentiment over all sentences\n",
    "       (4) the maximum positive sentiment over all sentences\n",
    "       (5) the maximum neutral sentiment over all sentences\n",
    "       (6) the maximum negative sentiment over all sentences\"\"\"\n",
    "    feat_matrix = numpy.empty((len(dataset), 6)) #row,col\n",
    "    for i in range(len(dataset)):\n",
    "        sentences = sent_tokenize(dataset[i]['reviewText'])\n",
    "        nsent = len(sentences)\n",
    "        if nsent:\n",
    "            sentence_polarities = numpy.empty((nsent, 3))\n",
    "            for j in range(nsent):\n",
    "                polarity = sia.polarity_scores(sentences[j])\n",
    "                sentence_polarities[j, 0] = polarity['pos']\n",
    "                sentence_polarities[j, 1] = polarity['neu']\n",
    "                sentence_polarities[j, 2] = polarity['neg']\n",
    "            feat_matrix[i, 0:3] = numpy.mean(sentence_polarities, axis=0) # mean over the columns\n",
    "            feat_matrix[i, 3:6] = numpy.max(sentence_polarities, axis=0) # maximum over the columns\n",
    "        else:\n",
    "            feat_matrix[i, 0:6] = 0.0\n",
    "    return feat_matrix\n",
    "\n",
    "sia_tr = sia_features(apps_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2244     0.7224     0.0532     0.667      1.         0.266     ]\n",
      " [0.27375    0.72625    0.         0.444      1.         0.        ]\n",
      " [0.11785714 0.878      0.00414286 0.804      1.         0.029     ]\n",
      " [0.38566667 0.61433333 0.         0.478      0.746      0.        ]\n",
      " [0.49133333 0.481      0.02766667 0.818      0.868      0.083     ]\n",
      " [0.266      0.734      0.         0.292      0.76       0.        ]\n",
      " [0.14755556 0.83111111 0.02133333 0.385      1.         0.119     ]\n",
      " [0.122      0.878      0.         0.244      1.         0.        ]\n",
      " [0.3155     0.6845     0.         0.5        0.869      0.        ]\n",
      " [0.26033333 0.73966667 0.         0.468      1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(sia_tr[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11.]]\n",
      "[ 8.  9. 10. 11.]\n",
      "[1.5 5.5 9.5]\n"
     ]
    }
   ],
   "source": [
    "### Just some numpy practice in the mean time!\n",
    "testmat = numpy.arange(12.).reshape((3, 4))\n",
    "print(testmat)\n",
    "print(numpy.max(testmat, axis=0))\n",
    "print(numpy.mean(testmat, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Adding the length feature* : if someone writes a REALLY long review, either they are REALLY satisfied or REALLY unhappy, but someone might also just want to write details of their experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_features(dataset):\n",
    "    \"\"\"Add two features:\n",
    "       (1) length of review (in thousands of characters) - truncate at 2,500\n",
    "           (cuz very long is very long anyways)\n",
    "       (2) percentage of exclamation marks (in %)\"\"\"\n",
    "    feat_matrix = numpy.empty((len(dataset), 2))\n",
    "    for i in range(len(dataset)):\n",
    "        text = dataset[i]['reviewText']\n",
    "        feat_matrix[i, 0] = len(text) / 1000.\n",
    "        if text:\n",
    "            feat_matrix[i, 1] = 100. * text.count('!') / len(text)\n",
    "        else:\n",
    "            feat_matrix[i, 1] = 0.0\n",
    "    feat_matrix[feat_matrix>2.5] = 2.5\n",
    "    return feat_matrix\n",
    "\n",
    "len_tr = len_features(apps_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451730, 2) (451730, 6) (451730, 2)\n"
     ]
    }
   ],
   "source": [
    "## previous and new features\n",
    "print(X_train_neg.shape, sia_tr.shape, len_tr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then predict with the original Linear regression (with negated data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the mean absolute error on the training data is 0.886206 stars\n"
     ]
    }
   ],
   "source": [
    "#stack horizontally(meaning combining all the features matrices - 1 old, and 2 new)\n",
    "X_train_augmented = numpy.concatenate((X_train_neg, sia_tr, len_tr), axis=1)\n",
    "# ^ this line is common for all, just making the X-train here\n",
    "lreg_augmented = LinearRegression().fit(X_train_augmented, Y_train)\n",
    "pred_train_augmented = lreg_augmented.predict(X_train_augmented)\n",
    "mae_train_augmented = mean_absolute_error(pred_train_augmented, Y_train)\n",
    "print(\"Now the mean absolute error on the training data is %f stars\" % mae_train_augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# :0 :0 :0 Error is now *88.62%* (2 features error was 97% and now is 10 features)\n",
    "original linear regression with neagation (with only fpos and fneg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Predict with 10 features (negated included) in Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the RF, it is 0.341048 stars\n"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "rf_augmented = RandomForestRegressor().fit(X_train_augmented, Y_train)\n",
    "rfpred_train_augmented = rf_augmented.predict(X_train_augmented)\n",
    "mae_train_rf_augmented = mean_absolute_error(rfpred_train_augmented, Y_train)\n",
    "print(\"For the RF, it is %f stars\" % mae_train_rf_augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOWAY!! Error: 34% ??!! WOAH! how come? Random forest is Awesome! (from previous RF 94%)\n",
    "### It was nltk sentiment analyzer + negation + 10 features + random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "#### Now finally we will run the best ML algo we found on our 'validation' set, to see if the algo really is a good predictor, or did the algo simply overfit the test set and therefore was showing really less error\n",
    "\n",
    "we will validate on the negation+the sia+the len feature set=10 features, like above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_neg = dataset_to_matrix_with_neg(apps_valid) #2 features\n",
    "sia_valid = sia_features(apps_valid) # 6 features\n",
    "len_valid = len_features(apps_valid) # 2 features\n",
    "\n",
    "X_valid_augmented = numpy.concatenate((X_valid_neg, sia_valid, len_valid), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear regression and random forest fitting\n",
    "pred_valid_augmented = lreg_augmented.predict(X_valid_augmented)\n",
    "pred_valid_rf_augmented = rf_augmented.predict(X_valid_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_valid = dataset_to_targets(apps_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the validation set, we get 0.892178 error for the linear regression\n",
      "And 0.872144 for the random forest regression\n"
     ]
    }
   ],
   "source": [
    "mae_valid_augmented = mean_absolute_error(pred_valid_augmented, Y_valid)\n",
    "print(\"On the validation set, we get %f error for the linear regression\" % mae_valid_augmented)\n",
    "mae_valid_rf_augmented = mean_absolute_error(pred_valid_rf_augmented, Y_valid)\n",
    "print(\"And %f for the random forest regression\" % mae_valid_rf_augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oh Damn! Linear Regression : TestSet=88.62% and ValidationSet=89.21%    RandomForest TestSet=34%, ValidationSet=87.21%\n",
    "Clearly Random forest overestimated :/ But Linear Regression actually *predicted* . Overall picture, random forest is still good, it **did** pick something up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework for certification\n",
    "\n",
    "Refactor the code above:\n",
    "\n",
    "\"*Be lazy. Not just lazy but proactively, agressively lazy.*\" Remove duplication. Create a single function that takes in data and spits out all success metrics across all of your algos.\n",
    "\n",
    "Where to go from here?\n",
    "- unigrams (NLTK)\n",
    "- word vector (gensim, glove, word2vec)\n",
    "- recurrent neural net\n",
    "- convolutional neural net\n",
    "<br>\n",
    "\n",
    "https://www.oreilly.com/learning/perform-sentiment-analysis-with-lstms-using-tensorflow\n",
    "\n",
    "http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/\n",
    "\n",
    "https://machinelearningmastery.com/develop-n-gram-multichannel-convolutional-neural-network-sentiment-analysis/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
